{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde590ab",
   "metadata": {},
   "source": [
    "This code is based on the SleepAccel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9967a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "from importSleepAccel import import_sleep_accel\n",
    "#%matplotlib ipympl\n",
    "\n",
    "import argparse\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54322c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the ids from a text file\n",
    "ids_df = pd.read_csv('../Data/SleepAccel/ids.txt', delimiter=\",\", header=None)\n",
    "\n",
    "\n",
    "ids = ids_df.iloc[0,:].tolist()\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f48fecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing id 8000685\n",
      "\tExtracted 974 epochs from id 8000685\n",
      "Processing id 6220552\n",
      "\tExtracted 1054 epochs from id 6220552\n",
      "Processing id 8686948\n",
      "\tExtracted 1015 epochs from id 8686948\n",
      "Processing id 1066528\n",
      "\tExtracted 773 epochs from id 1066528\n",
      "Processing id 844359\n",
      "\tExtracted 951 epochs from id 844359\n",
      "Processing id 1818471\n",
      "\tExtracted 1065 epochs from id 1818471\n",
      "Processing id 3997827\n",
      "\tExtracted 1040 epochs from id 3997827\n",
      "Processing id 1360686\n",
      "\tExtracted 980 epochs from id 1360686\n",
      "Processing id 5498603\n",
      "\tExtracted 863 epochs from id 5498603\n",
      "Processing id 781756\n",
      "\tExtracted 1023 epochs from id 781756\n",
      "Processing id 2598705\n",
      "\tExtracted 820 epochs from id 2598705\n",
      "Processing id 2638030\n",
      "\tExtracted 1069 epochs from id 2638030\n",
      "Processing id 9961348\n",
      "\tExtracted 990 epochs from id 9961348\n",
      "Processing id 7749105\n",
      "\tExtracted 229 epochs from id 7749105\n",
      "Processing id 4426783\n",
      "\tExtracted 1014 epochs from id 4426783\n",
      "Processing id 4314139\n",
      "\tExtracted 1012 epochs from id 4314139\n",
      "Processing id 9618981\n",
      "\tExtracted 262 epochs from id 9618981\n",
      "Processing id 759667\n",
      "\tExtracted 608 epochs from id 759667\n",
      "Processing id 46343\n",
      "\tExtracted 639 epochs from id 46343\n",
      "Processing id 9106476\n",
      "\tExtracted 1075 epochs from id 9106476\n",
      "Processing id 8173033\n",
      "\tExtracted 1047 epochs from id 8173033\n",
      "Processing id 8692923\n",
      "\tExtracted 1049 epochs from id 8692923\n",
      "Processing id 5132496\n",
      "\tExtracted 631 epochs from id 5132496\n",
      "Processing id 1455390\n",
      "\tExtracted 1041 epochs from id 1455390\n",
      "Processing id 3509524\n",
      "\tExtracted 552 epochs from id 3509524\n",
      "Processing id 8258170\n",
      "\tExtracted 0 epochs from id 8258170\n",
      "Processing id 4018081\n",
      "\tExtracted 547 epochs from id 4018081\n",
      "Processing id 5797046\n",
      "\tExtracted 1064 epochs from id 5797046\n",
      "Processing id 8530312\n",
      "\tExtracted 894 epochs from id 8530312\n",
      "Processing id 5383425\n",
      "\tExtracted 0 epochs from id 5383425\n",
      "Processing id 1449548\n",
      "\tExtracted 913 epochs from id 1449548\n"
     ]
    }
   ],
   "source": [
    "accel_epochs = []\n",
    "sleep_epochs = []\n",
    "for id in ids:\n",
    "    l = len(sleep_epochs)\n",
    "    print(f\"Processing id {id}\")\n",
    "    acc_df = pd.read_csv(f'../Data/SleepAccel/motion/{id}_acceleration.txt', delimiter=\" \", header=None)\n",
    "    acc_df = acc_df.to_numpy()\n",
    "    # Import sleep stage data\n",
    "    sleep_df = pd.read_csv(f'../Data/SleepAccel/labels/{id}_labeled_sleep.txt', delimiter=\" \", header=None).to_numpy()\n",
    "    epoch_length = 30\n",
    "    start_time = acc_df[0,0]\n",
    "    #Round the start time up to the nearest epoch\n",
    "    start_time = start_time + (epoch_length - (start_time % epoch_length))\n",
    "    # Get the end time using the earlier end time of accel_t or hr_t\n",
    "    end_time = acc_df[-1,0]\n",
    "    # Round the end time down to the nearest epoch\n",
    "    end_time = end_time - (end_time % epoch_length)\n",
    "\n",
    "    epoch_times = np.arange(start_time, end_time, epoch_length)\n",
    "    expected_length = 4.5*60 * 50 # 2.5 minutes of data at 50 Hz\n",
    "\n",
    "    length = int(4.5*60 * 50 - 50)\n",
    "    for et in epoch_times:\n",
    "        start = et - 120 # 2 minutes before the epoch\n",
    "        end = et + 150 # 2 minutes after the epoch\n",
    "        accel = acc_df[(acc_df[:,0] >= start) & (acc_df[:,0] <= end)]\n",
    "        if accel.shape[0] < expected_length - 50:  # If there are less than 99% of the expected samples, skip this epoch\n",
    "            #print(f\"\\tSkipping epoch at {et} due to insufficient data: {accel.shape[0]} samples\")\n",
    "            continue\n",
    "        \n",
    "        accel_epochs.append(accel[:length,1:4])  # Append only the x, y, z columns\n",
    "        sleep_epochs.append(sleep_df[sleep_df[:,0] == et, 1])  # Append the sleep stage for this epoch\n",
    "\n",
    "    print(f\"\\tExtracted {len(accel_epochs)-l} epochs from id {id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "463ab04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sleep_epochs)\n",
    "for i in range(len(sleep_epochs)):\n",
    "    if sleep_epochs[i].size > 0 and sleep_epochs[i][0] > 1:\n",
    "        sleep_epochs[i] = 1\n",
    "    else:\n",
    "        sleep_epochs[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_epochs = np.array(sleep_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61cc0209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25194, 13450, 3), (25194,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accel_epochs.shape, sleep_epochs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ddb8f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_7 (Conv1D)           (None, 13448, 32)         320       \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPoolin  (None, 6724, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 6722, 64)          6208      \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPoolin  (None, 3361, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 3359, 32)          6176      \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPoolin  (None, 1679, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 53728)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                1719328   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1732065 (6.61 MB)\n",
      "Trainable params: 1732065 (6.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(accel_epochs.shape[1], accel_epochs.shape[2])),\n",
    "    tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9848fd59",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m test_labels = sleep_epochs[\u001b[38;5;28mint\u001b[39m(\u001b[32m0.8\u001b[39m*\u001b[38;5;28mlen\u001b[39m(sleep_epochs)):]\n\u001b[32m      5\u001b[39m steps_per_epoch = \u001b[38;5;28mlen\u001b[39m(train_inputs) // \u001b[32m32\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/keras/src/engine/training.py:1721\u001b[39m, in \u001b[36mModel.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[39m\n\u001b[32m   1711\u001b[39m     \u001b[38;5;28mself\u001b[39m._cluster_coordinator = (\n\u001b[32m   1712\u001b[39m         tf.distribute.experimental.coordinator.ClusterCoordinator(\n\u001b[32m   1713\u001b[39m             \u001b[38;5;28mself\u001b[39m.distribute_strategy\n\u001b[32m   1714\u001b[39m         )\n\u001b[32m   1715\u001b[39m     )\n\u001b[32m   1717\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.distribute_strategy.scope(), training_utils.RespectCompiledTrainableState(  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m   1718\u001b[39m     \u001b[38;5;28mself\u001b[39m\n\u001b[32m   1719\u001b[39m ):\n\u001b[32m   1720\u001b[39m     \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1721\u001b[39m     data_handler = \u001b[43mdata_adapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1722\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1723\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1724\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1726\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[43m        \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1728\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1729\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1730\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1731\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1732\u001b[39m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1733\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1734\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1735\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1736\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1738\u001b[39m     \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[32m   1739\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module.CallbackList):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1688\u001b[39m, in \u001b[36mget_data_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1686\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(*args, **kwargs)\n\u001b[32m   1687\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1292\u001b[39m, in \u001b[36mDataHandler.__init__\u001b[39m\u001b[34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[39m\n\u001b[32m   1289\u001b[39m     \u001b[38;5;28mself\u001b[39m._steps_per_execution = steps_per_execution\n\u001b[32m   1291\u001b[39m adapter_cls = select_data_adapter(x, y)\n\u001b[32m-> \u001b[39m\u001b[32m1292\u001b[39m \u001b[38;5;28mself\u001b[39m._adapter = \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1294\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdistribute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1306\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1308\u001b[39m strategy = tf.distribute.get_strategy()\n\u001b[32m   1310\u001b[39m \u001b[38;5;28mself\u001b[39m._current_step = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:253\u001b[39m, in \u001b[36mTensorLikeDataAdapter.__init__\u001b[39m\u001b[34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    241\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    242\u001b[39m     x,\n\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m     **kwargs,\n\u001b[32m    251\u001b[39m ):\n\u001b[32m    252\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(x, y, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     x, y, sample_weights = \u001b[43m_process_tensorlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[32m    255\u001b[39m         sample_weights, sample_weight_modes\n\u001b[32m    256\u001b[39m     )\n\u001b[32m    258\u001b[39m     \u001b[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1163\u001b[39m, in \u001b[36m_process_tensorlike\u001b[39m\u001b[34m(inputs)\u001b[39m\n\u001b[32m   1160\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[32m   1161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m-> \u001b[39m\u001b[32m1163\u001b[39m inputs = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_single_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tf.__internal__.nest.list_to_tuple(inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/util/nest.py:629\u001b[39m, in \u001b[36mmap_structure\u001b[39m\u001b[34m(func, *structure, **kwargs)\u001b[39m\n\u001b[32m    543\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnest.map_structure\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap_structure\u001b[39m(func, *structure, **kwargs):\n\u001b[32m    545\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[32m    546\u001b[39m \n\u001b[32m    547\u001b[39m \u001b[33;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    627\u001b[39m \u001b[33;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mModality\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1168\u001b[39m, in \u001b[36mmap_structure\u001b[39m\u001b[34m(modality, func, *structure, **kwargs)\u001b[39m\n\u001b[32m   1071\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[32m   1072\u001b[39m \n\u001b[32m   1073\u001b[39m \u001b[33;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1165\u001b[39m \u001b[33;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m modality == Modality.CORE:\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m modality == Modality.DATA:\n\u001b[32m   1170\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, *structure, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1208\u001b[39m, in \u001b[36m_tf_core_map_structure\u001b[39m\u001b[34m(func, *structure, **kwargs)\u001b[39m\n\u001b[32m   1203\u001b[39m flat_structure = (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[32m   1204\u001b[39m entries = \u001b[38;5;28mzip\u001b[39m(*flat_structure)\n\u001b[32m   1206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[32m   1207\u001b[39m     structure[\u001b[32m0\u001b[39m],\n\u001b[32m-> \u001b[39m\u001b[32m1208\u001b[39m     \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentries\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m   1209\u001b[39m     expand_composites=expand_composites,\n\u001b[32m   1210\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1208\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1203\u001b[39m flat_structure = (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[32m   1204\u001b[39m entries = \u001b[38;5;28mzip\u001b[39m(*flat_structure)\n\u001b[32m   1206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[32m   1207\u001b[39m     structure[\u001b[32m0\u001b[39m],\n\u001b[32m-> \u001b[39m\u001b[32m1208\u001b[39m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[32m   1209\u001b[39m     expand_composites=expand_composites,\n\u001b[32m   1210\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1158\u001b[39m, in \u001b[36m_process_tensorlike.<locals>._convert_single_tensor\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1156\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x.dtype.type, np.floating):\n\u001b[32m   1157\u001b[39m         dtype = backend.floatx()\n\u001b[32m-> \u001b[39m\u001b[32m1158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m _is_scipy_sparse(x):\n\u001b[32m   1160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1258\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1260\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1262\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion.py:161\u001b[39m, in \u001b[36mconvert_to_tensor_v2_with_dispatch\u001b[39m\u001b[34m(value, dtype, dtype_hint, name)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m.tf_export(\u001b[33m\"\u001b[39m\u001b[33mconvert_to_tensor\u001b[39m\u001b[33m\"\u001b[39m, v1=[])\n\u001b[32m     97\u001b[39m \u001b[38;5;129m@dispatch\u001b[39m.add_dispatch_support\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[32m     99\u001b[39m     value, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    100\u001b[39m ) -> tensor_lib.Tensor:\n\u001b[32m    101\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[32m    102\u001b[39m \n\u001b[32m    103\u001b[39m \u001b[33;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m \u001b[33;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion.py:171\u001b[39m, in \u001b[36mconvert_to_tensor_v2\u001b[39m\u001b[34m(value, dtype, dtype_hint, name)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_hint\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[39m\n\u001b[32m    225\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    226\u001b[39m           _add_error_prefix(\n\u001b[32m    227\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for type \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret.dtype.base_dtype.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    231\u001b[39m               name=name))\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m   ret = \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[32m    237\u001b[39m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:328\u001b[39m, in \u001b[36m_constant_tensor_conversion_function\u001b[39m\u001b[34m(v, dtype, name, as_ref)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_constant_tensor_conversion_function\u001b[39m(v, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    326\u001b[39m                                          as_ref=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    327\u001b[39m   _ = as_ref\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[39m, in \u001b[36mconstant\u001b[39m\u001b[34m(value, dtype, shape, name)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m\"\u001b[39m, v1=[])\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstant\u001b[39m(value, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, shape=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[33m\"\u001b[39m\u001b[33mConst\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    172\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[32m    173\u001b[39m \n\u001b[32m    174\u001b[39m \u001b[33;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    265\u001b[39m \u001b[33;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[39m, in \u001b[36m_constant_impl\u001b[39m\u001b[34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[39m\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m trace.Trace(\u001b[33m\"\u001b[39m\u001b[33mtf.constant\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    278\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m const_tensor = ops._create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    282\u001b[39m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[32m    283\u001b[39m )\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[39m, in \u001b[36m_constant_eager_impl\u001b[39m\u001b[34m(ctx, value, dtype, shape, verify_shape)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[32m    288\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m   t = \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/mliot/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:90\u001b[39m, in \u001b[36mconvert_to_eager_tensor\u001b[39m\u001b[34m(value, ctx, dtype)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Converts the given `value` to an `EagerTensor`.\u001b[39;00m\n\u001b[32m     71\u001b[39m \n\u001b[32m     72\u001b[39m \u001b[33;03mNote that this function could return cached copies of created constants for\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     84\u001b[39m \u001b[33;03m  TypeError: if `dtype` is not compatible with the type of t.\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np.ndarray):\n\u001b[32m     87\u001b[39m   \u001b[38;5;66;03m# Make a copy explicitly because the EagerTensor might share the underlying\u001b[39;00m\n\u001b[32m     88\u001b[39m   \u001b[38;5;66;03m# memory with the input array. Without this copy, users will be able to\u001b[39;00m\n\u001b[32m     89\u001b[39m   \u001b[38;5;66;03m# modify the EagerTensor after its creation by changing the input array.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m   value = value.copy()\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ops.EagerTensor):\n\u001b[32m     92\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m value.dtype != dtype:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_inputs = accel_epochs[:int(0.8*len(accel_epochs))]\n",
    "train_labels = sleep_epochs[:int(0.8*len(sleep_epochs))]\n",
    "test_inputs = accel_epochs[int(0.8*len(accel_epochs)):]\n",
    "test_labels = sleep_epochs[int(0.8*len(sleep_epochs)):]\n",
    "steps_per_epoch = len(train_inputs) // 32\n",
    "history = model.fit(train_inputs, train_labels, batch_size=32, steps_per_epoch=steps_per_epoch, validation_data=(test_inputs, test_labels), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1c5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mliot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
